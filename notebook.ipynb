{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OllamaEmbeddings\nmodel\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_ollama\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OllamaEmbeddings\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m OllamaLLM(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOllamaEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a joke\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OllamaEmbeddings\nmodel\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "embeddings = OllamaEmbeddings()\n",
    "model.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'mlschool.pdf', 'page': 0}, page_content='Building Machine Learning Systems That Don\\'t\\nSuck\\nA live, interactive program that\\'ll help you build production-readymachine\\nlearning systems from the ground up.\\nNext cohort:\\xa0February3 - 20, 2025\\nCheck the schedulefor more details about upcoming cohorts.\\nI want to join! Sign in\\nLearn how to design, build, deploy, and scale machine learning\\nsystems to solve real-world problems.\\nI\\'ll lose my mind if I see another book or course teaching people the same basic\\nideas for the hundredth time. Most people are stuck in beginner mode, and finding\\nhelp to solve real-world problems is hard.\\nI want to change that.\\nI started writing software 30 years ago. I\\'ve written pipelines and trained models\\nfor some of the largest companies in the world. I want to show you how to do the\\nsame.\\nThis is the class I wish I had taken when I started.\\n\"This is the best machine learning course I\\'ve done.\\nWorth every cent.\"\\n— Jose Reyes, AI/ML at Cevo Australia\\n24/11/2024, 23:27 Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 1/10'),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 1}, page_content=\"This program will help you unlearn what you think machine learning is. It's a\\npractical, hands-on class where you'll learn from years of experience and real-\\nworld examples.\\nWhen you join, you get lifetime access to the following:\\n18 hours of live, interactive sessions. We'll use this time to discuss the first\\nprinciples behind building machine learning systems.\\n10 hours of step-by-step coding instructions. These practical sessions will\\nshow you how to build an end-to-end system from scratch.\\nA final project where you'll build a complete solution and receive direct\\nfeedback on your work.\\n100 coding assignments and practice questions.\\nThe entire source code of a working production system. It's yours. You can\\nchange and use it as you see fit.\\nA private community where you'll collaborate with thousands of people from\\ndifferent backgrounds.\\nDirect access to your instructor.\\nLifetime access to every past and future cohort.\\nProgram certificate upon completion.\\nAnd the best part is that you only pay once to join. There are no monthly fees. No\\nannual fees. No hidden costs. You pay once to join and benefit forever until the end\\nof time.\\nThe program won't be easy. It'll take time and effort. But if you want to use\\nmachine learning to solve real-world problems,this is the class you don't want to\\nmiss.\\nWho Is This Program For?\\nThis is a practical, hands-on program for technical professionals\\nwho are ready to put in the work.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 2/10\"),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 2}, page_content='This program is for software engineers,data scientists,data analysts,machine\\nlearning engineers,technical managers, and anyone anyone who wants to use\\nmachine learning to solve real-world problems.\\nHere are the criteria to succeed in the program:\\nYou have experience writing code. We\\'ll use Python throughout the class,\\nbut you won\\'t have any problems if you know any other language.\\nYou are familiar with basic machine learning terminology. This is not an\\nintroductory class. We\\'ll move quickly over the basics to focus on the\\nfundamental ideas that make systems work.\\nYou are ready to put in the work to succeed.\\n\"I have learned a ton from Santiago in his class and it was actually what helped inspire me\\nand get into the MLOps work that I\\'m doing now. Truly one of the most helpful online courses\\nfor doing real, full-scale machine learning.\"\\nBrian H. Hough\\nSoftware Engineer\\nWhat Will You Learn?\\nYou\\'ll come out with practical skills and insights into what it takes to\\nbuild systems that work in the real world.\\nHere is a summary of what makes this program unique:\\nYou\\'ll design and write the code to build an end-to-end machine learning\\nsystem starting from scratch.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 3/10'),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 3}, page_content=\"You'll learn best practices to tackle the most significant challenges machine\\nlearning engineers face to build, evaluate, run, monitor, and maintain\\nmachine learning systems in real-world scenarios.\\nYou'll learn how to use techniques like active learning, distributed training,\\nadversarial validation, human-in-the-loop deployments, model compression,\\ntest-time augmentation, testing in production, among many others.\\nYou'll learn how to create training, deploying, monitoring, and inference\\npipelines using Amazon SageMaker and open-source tools.\\nForget about theoretical concepts. This program will show you some of the things\\nI've learned from real-life examples I've built during more than 30 years in the\\nindustry.\\nCheck the program syllabus\\xa0→\\nReal-life examples and case studies\\nLearn from practical experience building machine\\nlearning systems that work in the real world.\\nLive, interactive sessions\\nAsk questions and interact with the instructor and\\nother students in real time.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 4/10\"),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 4}, page_content=\"Code walkthroughs\\nStep by step coding instructions to help you build\\na production system from scratch.\\nUpcoming Schedule\\nEvery iteration of the program gives you 18 hours of hands-on, live\\ntraining spread over 3 weeks.\\nHere are the upcoming cohorts:\\nCohort 17:February 3-February 20, 2025.10:00 AM EST\\nLive sessions will take place every Monday and Thursday at the same time. On\\nWednesdays, we'll host office hours when you can bring your questions projects\\nor anything else you want to discuss.\\nMonday: Live session. 2 hours.\\nTuesday: Individual work.\\nWednesday: Optional office hours.\\nThursday: Live session. 2 hours.\\nFriday: Individual work.\\nDo not wait for a specific cohort to join the program. You have lifetime access to\\nevery past and future cohort, and the sooner you join, the more time you have to\\nprepare.\\nEvery session is recorded. You can attend live or watch the recorded version later.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 5/10\"),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 5}, page_content='\"This is one of the best classes I\\'ve ever purchased over the internet. Santiago is a terrific\\nteacher. The ability he has to share knowledge is fantastic. I recommend this course. Worth\\n10x what he\\'s charging.\"\\nSal DiStefano\\nReady To Join The Program?\\nYou\\'ll get lifetime access. No monthly fees. No annual fees. No\\nhidden costs.\\n$500$300\\nPay once. Access forever.\\nPay once to join the program and get lifetime access. You can participate in as many\\niterations as you\\'d like. No restrictions.\\nJoin now\\nEnjoy 18 hours of live, interactive sessions\\nWatch 10 hours of step-by-step coding instructions\\nPractice with 100 coding assignments\\nAccess the complete source code of a production system\\nLearn how to start freelancing on Upwork\\nGet feedback and support from the community\\n24/11/2024, 23:27 Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 6/10'),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 6}, page_content=\"Program Syllabus\\nThis program will teach you the practical skills and insights that will\\nhelp you build machine learning systems.\\nHere are the contents of the six live sessions of the program:\\nSession 1 - How To Start (Almost) Any Project\\nWhat makes production machine learning different from what you've\\nlearned.\\nThe strategy to solve the right problem using the right solution.\\nCritical questions to ask before starting any project.\\nProblem framing, inversion, and the haystack principle for building\\nsuccessful applications.\\nThe first rule of machine learning engineering and how to start building.\\nData collection strategies. A technique to determine how much data you\\nneed.\\nThe problem of selection bias and how to deal with it.\\nLabeling data. Human annotations, natural labels and weak supervision.\\nActive learning using the uncertainty and diversity sampling strategies.\\nSession 2 - How to Build a Model\\nThe role of data cleaning and feature engineering to build better models.\\nTurning data into numbers using vectorization techniques.\\nProducing homogeneous features using normalization and standardization.\\nHandling and interpreting missing values using imputation techniques.\\nThe approach to choosing the best model to solve any problem.\\nRandom baselines and the zero-rule algorithm.\\nHow to use overfitting to build models that don't suck.\\nGet direct feedback from your instructor\\n24/11/2024, 23:27 Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 7/10\"),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 7}, page_content='Hyperparameter tuning and experiment tracking.\\nMeasuring the quality of your holdout set.\\nAn introduction to distributed training using data parallelism and model\\nparallelism.\\nSee the remaining sessions\\n\"This is an awesome course! This is my second round and I continue learning. I recommend it\\nwith complete confidence.\"\\nJuan Olano\\nMachine Learning Engineer\\nFrequently Asked Questions\\nIf you can\\'t find the answer to your question, please reach out on\\nsocial media and I\\'ll be happy to help.\\nHow long will it take to complete the program?\\nIf you are attending the live sessions, you should set aside a minimum of 4 hours\\nevery week during the three weeks of the program. This commitment will be\\nenough for engineer leaders or anyone not interested in the coding portion of the\\nprogram.\\nThose interested in implementing the concepts discussed in class should set aside\\n2 to 4 hours weekly to complete the code walkthroughs and work on the\\nassignments.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 8/10'),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 8}, page_content='Are live sessions recorded?\\nYes, we record every live session. You can decide when to attend classes live or\\ncatch up asynchronously later using the recording.\\nI\\'m a complete beginner. Is this program helpful for me?\\nThis program is not an introduction to machine learning.\\nWhile we\\'ll discuss many fundamental ideas behind machine learning, beginners\\nwill find the sessions go much faster than what\\'s optimal for them.\\nWhat does \"lifetime access\" mean?\\nYou only pay once to join the program and get immediate access to every past,\\npresent, and future cohort.\\nEvery new iteration of the program is better than the ones before. Many students\\ntake classes once and then join a later cohort to benefit from the updates.\\nThe lifetime access removes any pressure from having to complete the program\\nwhen life gets in the way.\\nHey! I\\'m Santiago.\\nI\\'m the instructor of the program.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 9/10'),\n",
       " Document(metadata={'source': 'mlschool.pdf', 'page': 9}, page_content=\"I'm a machine learning engineer with over two decades of experience\\nbuilding and scaling enterprise software and machine learning systems.\\nI love neural networks. I love to make them work at scale.\\nFrom 2009 to 2023, I built products for Disney, Boston Dynamics, IBM,\\nDell, G4S, Anheuser-Busch, and NextEra Energy, among other clients. I\\nlearned about trade-offs and how to create products that work.\\nI started this program in March 2023. Since then, thousands of students\\nhave graduated, and I can't wait to meet you in class.\\nCopyright © 2024 Tideily LLC\\nAll rights reserved.\\n24/11/2024, 23:27 Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 10/10\")]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"mlschool.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\".\n",
      "Context: Here is some context\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template=\"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt| model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_17700\\3226659032.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['context', 'question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Dhruv.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "    \"context\":\"The name I was given is Dhruv\",\n",
    "    \"question\":\"What's my name?\"\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"llama2\\\" not found, try pulling it first\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocArrayInMemorySearch\n\u001b[1;32m----> 2\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mDocArrayInMemorySearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_community\\vectorstores\\docarray\\in_memory.py:68\u001b[0m, in \u001b[0;36mDocArrayInMemorySearch.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an DocArrayInMemorySearch store and insert data.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    DocArrayInMemorySearch Vector Store\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_params(embedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_community\\vectorstores\\docarray\\base.py:82\u001b[0m, in \u001b[0;36mDocArrayIndex.add_texts\u001b[1;34m(self, texts, metadatas, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed texts and add to the vector store.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     81\u001b[0m ids: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 82\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (t, e) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(texts, embeddings)):\n\u001b[0;32m     84\u001b[0m     m \u001b[38;5;241m=\u001b[39m metadatas[i] \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_community\\embeddings\\ollama.py:214\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m--> 214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_community\\embeddings\\ollama.py:202\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_emb_response(prompt) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_community\\embeddings\\ollama.py:202\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_emb_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\ragsystem\\rag\\lib\\site-packages\\langchain_community\\embeddings\\ollama.py:176\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference API HTTP code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;241m%\u001b[39m (res\u001b[38;5;241m.\u001b[39mstatus_code, res\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     t \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mValueError\u001b[0m: Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"llama2\\\" not found, try pulling it first\"}"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages,\n",
    "    embedding = embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[0;32m      2\u001b[0m retriever\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine Learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m itemgetter\n\u001b[0;32m      2\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      3\u001b[0m     {\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m|\u001b[39m \u001b[43mretriever\u001b[49m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     }\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;241m|\u001b[39m model\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
